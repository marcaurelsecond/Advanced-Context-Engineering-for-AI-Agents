### General Guidelines for All Prompt Categories

These guidelines apply across all prompt types to ensure consistent, high-quality outputs and effective context management.

#### File Naming Conventions

**Standard Output Files:**
- `progress_summary.md` - Current state and next steps
- `research_summary.md` - System analysis and findings  
- `implementation_plan.md` - Detailed change plan
- `iteration_log.md` - Loop progress tracking
- `handoff_summary.md` - Context transfer between sessions

**Naming Rules:**
- Use lowercase with underscores
- Include descriptive suffixes (summary, plan, log)
- Date stamp for versioned files: `research_summary_2024-12-19.md`
- Keep names under 30 characters for readability

#### Context Window Management

**Monitoring Thresholds:**
- **Green Zone (0-25%)**: Normal operation, full detail allowed
- **Yellow Zone (25-40%)**: Start compacting, reduce verbosity
- **Red Zone (40%+)**: Immediate compaction required

**Compaction Strategies:**
- Archive detailed logs to separate files
- Use bullet points instead of paragraphs
- Reference external docs rather than copying content
- Focus on actionable items only
- Remove completed tasks from active context

#### Success Metrics Framework

**For All Prompts, Define:**
- **Completion Criteria**: What constitutes successful output
- **Quality Indicators**: How to measure output quality
- **Time Bounds**: Expected completion timeframes
- **Context Efficiency**: Target context usage percentages

**Universal Success Indicators:**
- Output is immediately actionable
- No clarifying questions needed from next agent
- Technical details are specific and accurate
- File paths and line numbers are correct
- Next steps are unambiguous

#### Failure Recovery Patterns

**Common Failure Points:**
- Vague or generic responses
- Missing technical specifics
- Context window overflow
- Incomplete task execution
- Loss of important context

**Recovery Strategies:**
- Provide specific examples of expected output
- Break complex tasks into smaller chunks
- Create checkpoint summaries at regular intervals
- Include rollback instructions for all changes
- Maintain audit trail of all decisions

#### Version Control Integration

**Git Workflow Considerations:**
- Create feature branches for experimental changes
- Commit frequently with descriptive messages
- Tag important milestones for easy rollback
- Include prompt outputs in commit messages for traceability

**Recommended Commit Structure:**
```
feat: implement user activity tracking

- Research phase: analyzed existing analytics system
- Planning phase: created implementation_plan.md
- Implementation: added UserActivity event to analytics.py
- Tests: added unit tests for new event type

Generated by: [Prompt Type] on [Date]
Context usage: [X%] at completion
```

#### Performance Optimization

**Speed Improvements:**
- Use structured templates for consistent formatting
- Pre-define common code patterns and snippets
- Maintain libraries of reusable prompt components
- Cache research results for similar tasks

**Quality Improvements:**
- Include validation steps in all prompts
- Require specific examples in outputs
- Use checklists for complex procedures
- Implement peer review for critical changes

#### Security and Safety

**Code Safety:**
- Never commit sensitive data or credentials
- Validate all external inputs and dependencies
- Include security considerations in all plans
- Test changes in isolated environments first

**Prompt Safety:**
- Avoid prompts that could lead to infinite loops
- Include termination conditions for autonomous tasks
- Set reasonable resource limits and timeouts
- Maintain human oversight for critical operations

#### Tool-Specific Adaptations

**For Different AI Tools:**
- Adapt context window thresholds based on tool capabilities
- Modify output formats for tool-specific features
- Leverage tool-native functions when available
- Account for tool-specific limitations and strengths

**Cross-Tool Compatibility:**
- Use standard markdown formatting
- Avoid tool-specific syntax in core prompts
- Include alternative approaches for different environments
- Test prompts across multiple AI platforms when possible